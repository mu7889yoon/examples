<!DOCTYPE html>
<html>
  <head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, shrink-to-fit=no"
    />
    <title>vLLM Chat</title>
    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/npm/@stlite/browser@0.90.0/build/stlite.css"
    />
  </head>
  <body>
    <div id="root"></div>
    <script type="module">
import { mount } from "https://cdn.jsdelivr.net/npm/@stlite/browser@0.90.0/build/stlite.js"
const origin = window.location.origin;
mount(
  {
    requirements: ["requests","asyncio"],
    entrypoint: "app.py",
    files: {
      "app.py": `
import streamlit as st
import json
import requests
import asyncio

ORIGIN = "${origin}"
MODEL_NAME = "Qwen/Qwen3-4B"
MAX_TOKENS = 512

st.set_page_config(
    page_title="vLLM Chat",
    page_icon="ğŸ¤–",
)

if "messages" not in st.session_state:
    st.session_state.messages = []

if "pending_prompt" not in st.session_state:
    st.session_state.pending_prompt = None


def call_vllm_api(prompt: str):
    try:
        response = requests.post(
            f"{ORIGIN}/v1/chat/completions",
            headers={"Content-Type": "application/json"},
            json={
                "model": MODEL_NAME,
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": MAX_TOKENS,
            },
        )
        response.raise_for_status()
        data = response.json()
        content = data["choices"][0]["message"]["content"]
        return content
    except Exception as e:
        return f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"


st.title("ğŸ¤– vLLM Chat")

with st.sidebar:
    st.markdown(f"**Model:** {MODEL_NAME}")
    st.markdown(f"**Endpoint:** {ORIGIN}")
    st.divider()
    if st.button("ä¼šè©±å±¥æ­´ã‚’ã‚¯ãƒªã‚¢"):
        st.session_state.messages = []
        st.rerun()

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if st.session_state.pending_prompt:
    pending = st.session_state.pending_prompt
    with st.chat_message("assistant"):
        with st.spinner("æ¨è«–ä¸­..."):
            await asyncio.sleep(0.01)
            response = call_vllm_api(pending)
            st.markdown(response)

    st.session_state.messages.append({"role": "assistant", "content": response})
    st.session_state.pending_prompt = None
    st.rerun()

if prompt := st.chat_input("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.session_state.pending_prompt = prompt
    st.rerun()
`,
    },
  },
  document.getElementById("root")
)
    </script>
  </body>  
</html>
